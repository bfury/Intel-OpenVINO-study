确保将MODEL-PATH设置到模型目录中。

eg: export lab_dir=~/

eg: export MODELS_PATH=~/??/??/models

使用的输入内容最好是将在产品中使用的视频，因为视频中实际操作量的大小会影响进行解码所需要的算力。如果是摄像头或RTSP流，应尽量去模拟真实对象。输出内容也需要符合这样的要求，如果用户需要实时查看输出视频，或者说可能需要存储或上传这一内容时，视频中实际操作量的大小同时会影响进行编码所需要的算力。如果不需要输出，则可以省去成本高昂的编码流程，或者编码为较低的分辨率、较低的帧速率，这些都会降低实际造成的影响。

为了让用户可以模拟整个流程，构建了DL-Streamer，Deep Learning Streamer是一个框架，可以用来构建计算图或流水线。它包含在2020.2以及更高版本的OpenVINO中，并且它还具有开源版本。用户可以将开发的视频分析元素添加至Gstreamer Elements的列表中，这些新元素利用OpenVINO进行检测、分类、识别跟踪、可视化等操作。DL-Streamer具有C++、Python和纯Gstreamer脚本示例。本实验介绍最简单的方法，直接编写简单的Gstreamer流水线代码，并在hands-on中运行代码。

每个模型都有几个版本：FP16、FP32、或者整型格式。**它们在不同设备上的速度各不相同**


执行命令vi face_detection_and_classification-file.sh查看代码。

可以看到本实验正在使用的模型名称，待使用的设备是CPU。

该代码为IR文件和JSON文件指定正确的路径。PIPELINE是流水线，采用源元素，即视频输入，对其进行解码和转换。第66行执行检测，然后执行3种不同的分类，最后输出视频文件。



