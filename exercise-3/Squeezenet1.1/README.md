1、使用模型优化器生成IR文件。

2、使用python分类示例对图像进行分类。

模型优化器（Model Optimizer）和推理引擎（Inference Engine）是整个工具套件的核心。

模型优化器是一个跨平台的命令行工具，可促进训练和部署环境之间的转换，执行静态模型分析并自动调整深度学习模型，以便在端点目标设备上实现最佳执行。模型优化器旨在支持多种深度学习支持的框架和格式。在运行模型优化器时，无需考虑要使用的目标设备，MO的相同输出可用于所有目标。模型优化器支持的框架和格式有Caffe（大多数公共分支机构）、TensorFlow、MXNet、Kaldi、ONNX。模型优化器工作流程：

为支持的深度学习框架配置模型优化器，该框架用于训练模型。
提供特定的网络拓扑，调整后的权重和偏差（带有一些可选参数）的训练网络作为输入。
运行模型优化器以执行特定的模型优化（例如，某些网络层的水平融合）。精确优化是特定于框架的，具体可参考Intel官网相应的页面：转换Caffe模型，转换TensorFlow模型，转换MXNet模型，转换Kaldi模型，转换ONNX模型。
模型优化器生成网络的中间表示（IR）作为输出，该网络用作所有目标上的推理引擎的输入。IR是一对描述整个模型的文件：

①　.xml：拓扑文件，描述网络拓扑的XML文件

②　.bin：经过训练的数据文件，包含权重和偏差二进制数据的.bin文件
推理引擎是提供统一的API以将推理与应用程序逻辑集成，主要作用如下：

作为模型的输入。该模型以模型优化器生成的中间表示（IR）的特定形式呈现。
优化目标硬件的推理执行。
在嵌入式推理平台上提供减少占用空间的推理解决方案。